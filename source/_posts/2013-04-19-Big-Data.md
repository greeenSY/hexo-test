---
layout: post
title: 大数据学习笔记
description: 最近一段时间对于大数据的入门级了解情况总结，涉及Hadoop、HDFS、MapReduce、Spark等
category: 大数据
tags: [分布式系统,Hadoop,Spark]
---


最近参加了几次和大数据相关的讲座和课程，渐渐地对于这个越来越热的方向产生了兴趣，于是对这几次的学习做了个二次消化，整理了一个学习笔记。

## 大数据

### 什么是大数据？

首先，什么是大数据？

[Wiki][1]上的解释是这样的：

巨量资料(big data)，或称大数据、海量资料，指的是所涉及的资料量规模巨大到无法透过目前主流软件工具，在合理时间内达到撷取、管理、处理、并整理成为帮助企业经营决策更积极目的的资讯。 大数据的4V特点：Volume、Velocity、Variety、Veracity。

“大数据”是由数量巨大、结构复杂、类型众多数据构成的数据集合，是基于云计算的数据处理与应用模式，通过数据的整合共享，交叉复用,形成的智力资源和知识服务能力。

### 大数据的特点

大数据有四方面特点：

1. 容量：数量大并且仍在爆发性增长，已经逐渐由TB级向PB级转移，需要更智能（并非强力）的大规模并行处理，同时非结构话的数据迅速增长（是结构化数据增长速度的10~50倍）并占到总数据量的80%以上。
2. 速度：实时分析而非批量分析，数据的存入、分析与删除都有着实时性的需求，需要立竿见影。
3. 多样性：大数据的异构与多变性质，不同形式（文本、视频、图片、文档），无计划或缺乏计划，不连贯的语法和语义。
3. 价值：对未来趋势与模式的可预测分析。

### 大数据的挑战

挑战主要在三个方面：

* Data is Big
* Data is Dirty
* Complex question

第一方面不用多说，数据量大并且爆发式增长。第二方面说Dirty是因为数据存在异构方面的问题，同时多种不同数据类型导致无模式、不一致的语法和语义，使得传统的方法无法处理。第三方面是复杂的问题：智能交通、价值分析、分布式并行计算、实时（real-time）性处理、open-ended问题等。

## Hadoop

### Hadoop简介

注，此部分内容主要摘选自

* [百度百科][2]
* [Xiaojun Liu's Blog][3]

Hadoop是Apache软件基金会所研发的开放源码并行运算编程工具和分散式档案系统，根据Google公司发表的MapReduce和Google档案系统的论文，自行实作而成。

Hadoop使得户可以在不了解分布式底层细节的情况下，开发分布式程序，充分利用集群的威力高速运算和存储。

Hadoop 是Apache 下的一个项目，由HDFS、MapReduce、HBase、Hive 和ZooKeeper等成员组成。其中，HDFS 和MapReduce 是两个最基础最重要的成员。

### Hadoop的优点

Hadoop是一个能够让用户轻松架构和使用的分布式计算平台。用户可以轻松地在Hadoop上开发和运行处理海量数据的应用程序。它主要有以下几个优点：

1. 高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。
2. 高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。
3. 高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。
4. 高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。

### Hadoop的架构

Hadoop 有许多元素构成。其最底部是 Hadoop Distributed File System（HDFS），它存储 Hadoop 集群中所有存储节点上的文件。HDFS（对于本文）的上一层是 MapReduce 引擎，该引擎由 JobTrackers 和 TaskTrackers 组成。

## HDFS

对外部客户机而言，HDFS 就像一个传统的分级文件系统。可以创建、删除、移动或重命名文件，等等。但是 HDFS 的架构是基于一组特定的节点构建的（如下图），这是由它自身的特点决定的。这些节点包括 NameNode（仅一个），它在 HDFS 内部提供元数据服务；DataNode，它为 HDFS 提供存储块。由于仅存在一个 NameNode，因此这是 HDFS 的一个缺点（单点失败）。存储在 HDFS 中的文件被分成块，然后将这些块复制到多个计算机中（DataNode）。这与传统的 RAID 架构大不相同。块的大小（通常为 64MB）和复制的块数量在创建文件时由客户机决定。NameNode 可以控制所有文件操作。HDFS 内部的所有通信都基于标准的 TCP/IP 协议。

![HDFS1](/images/BigData/HDFS1.jpg)

### HDFS基本原理

采用Master/Slave 结构。NameNode 维护集群内的元数据，对外提供创建、打开、删除和重命名文件或目录的功能。DataNode 存储数据，并提负责处理数据的读写请求。DataNode定期向NameNode 上报心跳，NameNode 通过响应心跳来控制DataNode。

![HDFS2](/images/BigData/HDFS2.jpg)

### NameNode

NameNode 是一个通常在 HDFS 实例中的单独机器上运行的软件。它负责管理文件系统名称空间和控制外部客户机的访问。NameNode 决定是否将文件映射到 DataNode 上的复制块上。对于最常见的 3 个复制块，第一个复制块存储在同一机架的不同节点上，最后一个复制块存储在不同机架的某个节点上。注意，这里需要您了解集群架构。实际的 I/O事务并没有经过 NameNode，只有表示 DataNode 和块的文件映射的元数据经过 NameNode。当外部客户机发送请求要求创建文件时，NameNode 会以块标识和该块的第一个副本的 DataNode IP 地址作为响应。这个 NameNode 还会通知其他将要接收该块的副本的 DataNode。

NameNode 在一个称为 FsImage 的文件中存储所有关于文件系统名称空间的信息。这个文件和一个包含所有事务的记录文件（这里是 EditLog）将存储在 NameNode 的本地文件系统上。FsImage 和 EditLog 文件也需要复制副本，以防文件损坏或 NameNode 系统丢失。

NameNode本身不可避免地具有SPOF（Single Point Of Failure）单点失效的风险，主备模式并不能解决这个问题，目前只有通过Hadoop Non-stop namenode才能实现100% uptime可用时间。

### DataNode

DataNode 也是一个通常在 HDFS 实例中的单独机器上运行的软件。Hadoop 集群包含一个 NameNode 和大量 DataNode。DataNode 通常以机架的形式组织，机架通过一个交换机将所有系统连接起来。Hadoop 的一个假设是：机架内部节点之间的传输速度快于机架间节点的传输速度。

DataNode 响应来自 HDFS 客户机的读写请求。它们还响应来自 NameNode 的创建、删除和复制块的命令。NameNode 依赖来自每个 DataNode 的定期心跳（heartbeat）消息。每条消息都包含一个块报告，NameNode 可以根据这个报告验证块映射和其他文件系统元数据。如果 DataNode 不能发送心跳消息，NameNode 将采取修复措施，重新复制在该节点上丢失的块。

### 文件操作

可见，HDFS 并不是一个万能的文件系统。它的主要目的是支持以流的形式访问写入的大型文件。如果客户机想将文件写到 HDFS 上，首先需要将该文件缓存到本地的临时存储。如果缓存的数据大于所需的 HDFS 块大小，创建文件的请求将发送给 NameNode。NameNode 将以 DataNode 标识和目标块响应客户机。同时也通知将要保存文件块副本的 DataNode。当客户机开始将临时文件发送给第一个 DataNode 时，将立即通过管道方式将块内容转发给副本 DataNode。客户机也负责创建保存在相同 HDFS名称空间中的校验和（checksum）文件。在最后的文件块发送之后，NameNode 将文件创建提交到它的持久化元数据存储（在 EditLog 和 FsImage 文件）。

### Linux 集群

Hadoop 框架可在单一的 Linux 平台上使用（开发和调试时），但是使用存放在机架上的商业服务器才能发挥它的力量。这些机架组成一个 Hadoop 集群。它通过集群拓扑知识决定如何在整个集群中分配作业和文件。Hadoop 假定节点可能失败，因此采用本机方法处理单个计算机甚至所有机架的失败。

## MapReduce

### 基本原理

InfoWord 将MapReduce 评为2009 年十大新兴技术的冠军。MapReduce 是大规模数据（TB 级）计算的利器，Map 和Reduce 是它的主要思想，来源于函数式编程语言，它的基本原理如下图所示：
 
![MapReduce1](/images/BigData/MapReduce1.jpg)

Map 负责将数据打散，Reduce负责对数据进行聚集，用户只需要实现map 和reduce 两个接口，即可完成TB 级数据的计算，常见的应用包括：日志分析和数据挖掘等数据分析应用。另外，还可用于科学数据计算，如圆周率PI 的计算等。

### MapReduce过程说明

首先来看一看一个MapReduce系统对外的接口。

* Map函数： map(String  key,  String  value) .....
* Reduce函数： reduce(String  key,  Iterator  values) .....

了解MapReduce模型的人应该知道，Map函数的输出是一系列的Key/Value对（pair），这些Key/Value对是给Reduce函数使用的。但是在这里可以发现，Map函数的输入参数也是Key和Value。但其实，输入的Key/Value和输出的Key/Value不是同一组东西。对于一个Map函数调用，输入的是一个Key/Value对，而输出呢，是一组Key/Value对。举例来说，如果要统计一篇文章中所有单词的数目，那么输入的Key可能就是行数，输入的Value就是该行的内容。对于一次Map调用，就是要统计出一行中各个单词出现的次数，所以输出的Key是单词，Value是这个单词的出现次数。

Map函数的输入之所以也用Key/Value的形式，可能是因为一般来说一个任务并不是用一次MapReduce就能够完成，而是需要用到多次MapReduce调用，下一个Map调用的输入很有可能就是上一个Reduce的输出结果（Key/Value对）。

以上摘自: [eros的linux平台技术资料库][4]

虽然mapreduce说是map和reduce两方面是他的主要思想，但是其处理过程却需要分为map、shuffle、reduce三个阶段：

1. Map过程是将输入映射为一系列新的的key/value对，简单来说就是映射。
2. Shuffle的正常意思是洗牌或弄乱，Shuffle描述着数据从map task输出到reduce task输入的这段过程。它根据key进行分组并有序地送入Reduce（这里框架自行进行了排序的过程，不需要用户来关心），其实shuffle受到关注是因为在这个过程中产生的网络开销成为很多mapreduce程序的效率瓶颈。
3. Reduce过程是对key进行统计计算并产生一个新的value。

### MapReduce原理详解

这里再引用百度百科中的一个原理说明：
 
![MapReduce2](/images/BigData/MapReduce2.jpg)

上图是论文里给出的流程图。一切都是从最上方的user program开始的，user program链接了MapReduce库，实现了最基本的Map函数和Reduce函数。图中执行的顺序都用数字标记了。

1. MapReduce库先把user program的输入文件划分为M份（M为用户定义），每一份通常有16MB到64MB，如图左方所示分成了split0~4；然后使用fork将用户进程拷贝到集群内其它机器上。

2. user program的副本中有一个称为master，其余称为worker，master是负责调度的，为空闲worker分配作业（Map作业或者Reduce作业），worker的数量也是可以由用户指定的。

3. 被分配了Map作业的worker，开始读取对应分片的输入数据，Map作业数量是由M决定的，和split一一对应；Map作业从输入数据中抽取出键值对，每一个键值对都作为参数传递给map函数，map函数产生的中间键值对被缓存在内存中。

4. 缓存的中间键值对会被定期写入本地磁盘，而且被分为R个区，R的大小是由用户定义的，将来每个区会对应一个Reduce作业；这些中间键值对的位置会被通报给master，master负责将信息转发给Reduce worker。

5. master通知分配了Reduce作业的worker它负责的分区在什么位置（肯定不止一个地方，每个Map作业产生的中间键值对都可能映射到所有R个不同分区），当Reduce worker把所有它负责的中间键值对都读过来后，先对它们进行排序，使得相同键的键值对聚集在一起。因为不同的键可能会映射到同一个分区也就是同一个Reduce作业（谁让分区少呢），所以排序是必须的。

6. reduce worker遍历排序后的中间键值对，对于每个唯一的键，都将键与关联的值传递给reduce函数，reduce函数产生的输出会添加到这个分区的输出文件中。

7. 当所有的Map和Reduce作业都完成了，master唤醒正版的user program，MapReduce函数调用返回user program的代码。

所有执行完毕后，MapReduce输出放在了R个分区的输出文件中（分别对应一个Reduce作业）。用户通常并不需要合并这R个文件，而是将其作为输入交给另一个MapReduce程序处理。整个过程中，输入数据是来自底层分布式文件系统（GFS）的，中间数据是放在本地文件系统的，最终输出数据是写入底层分布式文件系统（GFS）的。而且我们要注意Map/Reduce作业和map/reduce函数的区别：Map作业处理一个输入数据的分片，可能需要调用多次map函数来处理每个输入键值对；Reduce作业处理一个分区的中间键值对，期间要对每个不同的键调用一次reduce函数，Reduce作业最终也对应一个输出文件。


### 两个应用案例：

1.Word count

对于抓取的一系列页面，我们对页面中出现的词进行统计。
基本过程如下：

首先，对于每个页面我们作为一个key，内容作为value进入map函数，这里map的工作就是进行分词，每个词产生一个key，value为1输出。

然后利用MapReduce框架，把word汇聚（shuffle）和分块。

最后，对于相同的key并计算出一个新的value（reduce）。

最后我们得到的是每个词以及它的出现次数。

2.Filtered word count

这里不仅仅要进行word的统计，同时要进行敏感词的筛除，如果敏感词表较小的时候我们直接查表就可以解决，但是如果敏感词表较大或者不明规模的时候这么处理就不太现实。

同上面的word count的方法，我们这里需要的改动是：把blacklist（敏感词表）作为输入同其他word一同进行map，不同在于blacklist中的word输出不是（key，1）而是（key，0），在shuffle过程中我们遇见value为0的key则直接过滤掉。

## 其他相关知识整理：

### Hadoop相关：

Hadoop：如上介绍，Hadoop是Apache软件基金会所研发的开放源码并行运算编程工具和分散式档案系统，根据Google公司发表的MapReduce和Google档案系统的论文，自行实作而成。由HDFS、MapReduce、HBase、Hive 和ZooKeeper等成员组成。其中，HDFS 和MapReduce 是两个最基础最重要的成员。

MapReduce：如上介绍，MapReduce是Google提出的一个软件架构，用于大规模数据集（大于1TB）的并行运算。概念“Map（映射）”和“Reduce（化简）”，及他们的主要思想，都是从函数式编程语言借来的，还有从矢量编程语言借来的特性。

HDFS: 如上介绍，Hadoop Distributed File System，简称HDFS，是一个分布式文件系统。HDFS 是Google GFS 的开源版本，一个高度容错的分布式文件系统，它能够提供高吞吐量的数据访问，适合存储海量（PB 级）的大文件（通常超过64M）。

GFS: GFS 也就是 google File System，google公司为了存储海量搜索数据而设计的专用文件系统。

HIVE: hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。Hive 的数据存储在 HDFS 中，大部分的查询由 MapReduce 完成（包含 * 的查询，比如 select * from tbl 不会生成 MapRedcue 任务）。

HBase:HBase(Hadoop database)是一个分布式的、面向列的开源数据库，该技术来源于Chang et al所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。利用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。
 
![Hadoop](/images/BigData/Hadoop.jpg)

上图描述Hadoop EcoSystem中的各层系统其中,HBase位于结构化存储层，Hadoop HDFS为HBase提供了高可靠性的底层存储支持，Hadoop MapReduce为HBase提供了高性能的计算能力，Zookeeper为HBase提供了稳定服务和failover机制。此外，Pig和Hive还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单。 Sqoop则为HBase提供了方便的RDBMS数据导入功能，使得传统数据库数据向HBase中迁移变的非常方便。

ZooKeeper：ZooKeeper是Hadoop的正式子项目，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

PIG： Pig是一种编程语言，它简化了Hadoop常见的工作任务，并且提供一个更高层次抽象的数据处理能力，同时能够保持hadoop的简单和可靠性。Pig可加载数据、表达转换数据以及存储最终结果。Pig内置的操作使得半结构化数据变得有意义（如日志文件）。同时Pig可扩展使用Java中添加的自定义数据类型并支持数据转换。（Yahoo贡献）

Sqoop：Sqoop是一个用来将Hadoop和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。

MPI：MPI是一种标准或规范的代表，而不特指某一个对它的具体实现，迄今为止，所有的并行计算机制造商都提供对MPI的支持，可以在网上免费得到MPI在不同并行计算机上的实现，一个正确的MPI程序可以不加修改地在所有的并行机上运行；MPI是一种基于消息传递机制的并行编程标准，它为程序设计者提供了丰富而方便的通信函数，在程序设计上非常简单而且符合普通程序员的编程习惯。

### AMPLab（Berkeley）数据分析系统相关

这里给大家上Berkeley 数据分析系统的架构图，其中蓝色部分为Berkeley AMPLab的成果，白色部分为第三方提供：

![Berkeley](/images/BigData/Berkeley.jpg)

Spark：Spark 是面向再利用工作数据集的应用的内存集群计算框架，由加州大学伯克利分校 AMP 实验室 (Algorithms, Machines, and People Lab) 开发，可用来构建大型的、低延迟的数据分析应用程序。Spark  是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越（比如复杂任务、交互式查询、在线处理），换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。尽管创建 Spark 是为了支持分布式数据集上的迭代作业，但是实际上它是对 Hadoop 的补充，可以在 Hadoo 文件系统中并行运行。通过名为 Mesos 的第三方集群框架可以支持此行为。Spark 还引进了名为 弹性分布式数据集 (RDD) 的抽象。RDD 是分布在一组节点中的只读对象集合。这些集合是弹性的，如果数据集一部分丢失，则可以对它们进行重建。

mesos：资源管理平台，见spark。

RDD:弹性分布式数据集,"可恢复、分布式数据集”。RDD 是分布在一组节点中的只读对象集合，发生故障后可自动重新构建。存储大型工作数据集，基于“数据沿袭”的容错机制。

Shark：Shark = spark + hive。利用Spark的内存RDD缓存和灵活的语言功能：结果再利用和低延迟。可拓展，可容错，速度快，查询功能兼容Hive。

PIQL：PIQL is a SQL like language that uses a new scale independent optimization strategy to execute relational queries while maintaining the performance predicability and scalability provided by distributed key/value stores.  （[AMPLab实验室的说明][5]，我就不献丑翻译了）

SCADS：不依赖规模的存储系统。

### 其他

GRAPHLAB：GraphLab 是一个机器学习平台，主要是图模型方面的计算。GraphLab 是另一种有趣的MapReduce抽象实现，侧重机器学习算法的并行实现。GraphLab中，Map阶段定义了可以独立执行（在独立的主机上）的计算，Reduce阶段合并这些计算结果。

Twister：Twister是美国印第安纳大学对Hadoop的改良研究，主要针对Hadoop迭代的改良。

Pregel：Pregel是一个用于分布式图计算的计算框架，主要用于图遍历（BFS）、最短路径（SSSP）、PageRank计算等等。

Sawzall：作为一种查询语言，Sawzall是一种类型安全的脚本语言。由于Sawzall自身处理了很多问题，所以完成相同功能的代码就简化了非常多-与MapReduce的C++代码相比简化了10倍不止。（Google贡献）

Dryad&DryadLINQ：Dryad是一个在计算机集群或数据中心里并行地执行顺序程序的基础架构。DryadLINQ是“一个把LINQ程序转化成分布式计算指令，以便运行于PC集群的编译器”。这个转化过程可以分解为以下几步：C#和LINQ数据对象转化为分布式的文件块；LINQ查询转化为分布式Dryad任务；C#方法转化为运行于Dryad任务节点上的代码。（Microsoft贡献，不开源）

Dremel：Dremel 是Google 的“交互式”数据分析系统。可以组建成规模上千的集群，处理PB级别的数据。Google开发了Dremel将处理时间缩短到秒级，作为MapReduce的有力补充。Dremel是Google BigQuery的report引擎。Dremel是一种分析信息的方式，Dremel可跨越数千台服务器运行，允许“查询”大量的数据，如Web文档集合或数字图书馆，甚至是数以百万计的垃圾信息的数据描述。这类似于使用结构化查询语言分析传统关系数据库，这种方式在过去几十年被广泛使用在世界各地。（Google）

Impala：Impala是运行于现有Hadoop基础设施上的实时互动SQL查询引擎，可以让Hdadoop DFS文件系统以及Apache HBase数据库中的数据支持实时查询。解决Hadoop批处理延迟问题（据称比原来基于MapReduce的Hive SQL查询速度提升3～30倍）。

Storm：一个分布式的、容错的实时计算系统，简单的编程模型。类似于MapReduce降低了并行批处理复杂性，Storm降低了进行实时处理的复杂性。可以使用各种编程语言。（Twitter）

APACHE S4：Apache S4是一个常规用途的、分布式的、可伸缩的、容错的、可插入式的平台用于处理联系的无限数据流。Apache S4填补了复杂的专有系统和面向批处理的开源计算平台之间的差距。目标是开发高性能计算平台从应用编程的并行处理系统中固有的复杂性隐藏。Apache S4 已经在 Yahoo 的系统中使用，用于处理每秒数以千计的搜索查询。

最后，还有一张Intel在IDF2013技术峰会上展示的一张Intel Apache Hadoop软件分发版的架构图。

![Intel](/images/BigData/Intel.jpg)

## 主要参考资料

* [大数据 的 Wiki][1]
* [Hadoop的百度百科][2]
* [Xiaojun Liu's Blog][3]
* [eros的linux平台技术资料库][4]
* [AMPLab][5]

其他相关资料比较零碎，不方便列举，这里尤其感谢Google和百度的搜索结果。

[1]: http://zh.wikipedia.org/wiki/%E5%A4%A7%E6%95%B8%E6%93%9A
[2]: http://baike.baidu.com/view/908354.htm
[3]: http://www.cnblogs.com/liuxiaojun/archive/2010/09/06/hadoop-001.htm
[4]: http://blog.csdn.net/eroswang/article/details/6049637
[5]: https://amplab.cs.berkeley.edu/


